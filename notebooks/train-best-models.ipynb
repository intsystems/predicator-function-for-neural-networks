{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:05.472113Z",
     "iopub.status.busy": "2025-05-09T15:55:05.471565Z",
     "iopub.status.idle": "2025-05-09T15:55:18.147836Z",
     "shell.execute_reply": "2025-05-09T15:55:18.146954Z",
     "shell.execute_reply.started": "2025-05-09T15:55:05.472075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install filelock --quiet --break-system-packages\n",
    "# !pip install nni --quiet --break-system-packages\n",
    "# !pip install torch --quiet --break-system-packages\n",
    "# !pip install torchvision --quiet --break-system-packages\n",
    "# !pip install numpy --quiet --break-system-packages\n",
    "# !pip install matplotlib --quiet --break-system-packages\n",
    "# !pip install tqdm --quiet --break-system-packages\n",
    "# !pip install json --quiet --break-system-packages\n",
    "# !pip install os --quiet --break-system-packages\n",
    "# !pip install random --quiet --break-system-packages\n",
    "# !pip install wandb --quiet --break-system-packages\n",
    "# !pip install pytorch-lightning --quiet --break-system-packages\n",
    "# !pip install torchmetrics --quiet --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:18.149843Z",
     "iopub.status.busy": "2025-05-09T15:55:18.149546Z",
     "iopub.status.idle": "2025-05-09T15:55:32.926663Z",
     "shell.execute_reply": "2025-05-09T15:55:32.926064Z",
     "shell.execute_reply.started": "2025-05-09T15:55:18.149801Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from nni.nas.evaluator.pytorch import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from nni.nas.evaluator.pytorch import Classification\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from nni.nas.hub.pytorch import DARTS as DartsSpace\n",
    "from nni.nas.space import model_context\n",
    "from nni.nas.evaluator.pytorch import ClassificationModule\n",
    "from nni.nas.evaluator.pytorch import Lightning, Trainer\n",
    "\n",
    "from darts_classification_module import DartsClassificationModule\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from nni.nas.evaluator.pytorch import ClassificationModule\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:32.927682Z",
     "iopub.status.busy": "2025-05-09T15:55:32.927449Z",
     "iopub.status.idle": "2025-05-09T15:55:38.930543Z",
     "shell.execute_reply": "2025-05-09T15:55:38.929802Z",
     "shell.execute_reply.started": "2025-05-09T15:55:32.927662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdemoren\u001b[0m (\u001b[33mdemoren_mipt\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"ca0f522a70ce0bd6b4a0aeb32424470b576c24d3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:38.932565Z",
     "iopub.status.busy": "2025-05-09T15:55:38.932168Z",
     "iopub.status.idle": "2025-05-09T15:55:45.249452Z",
     "shell.execute_reply": "2025-05-09T15:55:45.248853Z",
     "shell.execute_reply.started": "2025-05-09T15:55:38.932547Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "])\n",
    "\n",
    "train_data = nni.trace(CIFAR10)(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "num_samples = len(train_data)\n",
    "indices = np.random.permutation(num_samples)\n",
    "split = int(num_samples * 0.8)\n",
    "\n",
    "search_train_loader = DataLoader(\n",
    "    train_data, batch_size=96, num_workers=4,\n",
    "    sampler=SubsetRandomSampler(indices[:split]),\n",
    ")\n",
    "\n",
    "search_valid_loader = DataLoader(\n",
    "    train_data, batch_size=96, num_workers=4,\n",
    "    sampler=SubsetRandomSampler(indices[split:]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:45.250315Z",
     "iopub.status.busy": "2025-05-09T15:55:45.250113Z",
     "iopub.status.idle": "2025-05-09T15:55:45.280089Z",
     "shell.execute_reply": "2025-05-09T15:55:45.279546Z",
     "shell.execute_reply.started": "2025-05-09T15:55:45.250299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_json_from_directory(directory_path):\n",
    "    json_data = []\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    try:\n",
    "                        data = json.load(f)\n",
    "                        json_data.append(data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON from file {file_path}: {e}\")\n",
    "    return json_data\n",
    "    \n",
    "arch_dicts = load_json_from_directory('../home/best_models_greed_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T15:55:45.291491Z",
     "iopub.status.busy": "2025-05-09T15:55:45.291252Z",
     "iopub.status.idle": "2025-05-09T15:55:45.310374Z",
     "shell.execute_reply": "2025-05-09T15:55:45.309672Z",
     "shell.execute_reply.started": "2025-05-09T15:55:45.291465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    architecture, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    max_epochs=600, \n",
    "    learning_rate=0.025, \n",
    "    project_name=\"neural_ensemble_search_6\",\n",
    "    run_name=None,\n",
    "    fast_dev_run=False\n",
    "):\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        name=run_name or str(architecture),\n",
    "        config={\n",
    "            \"architecture\": str(architecture),\n",
    "            \"max_epochs\": max_epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": 3e-4,\n",
    "            \"fast_dev_run\": fast_dev_run\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    with model_context(architecture):\n",
    "        model = DartsSpace(width=16, num_cells=10, dataset='cifar')\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    evaluator = Lightning(\n",
    "        DartsClassificationModule(\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=3e-4,\n",
    "            auxiliary_loss_weight=0.4,\n",
    "            max_epochs=max_epochs\n",
    "        ),\n",
    "        trainer=Trainer(\n",
    "            gradient_clip_val=5.0,\n",
    "            max_epochs=max_epochs,\n",
    "            fast_dev_run=fast_dev_run,\n",
    "            logger=WandbLogger(experiment=wandb.run)\n",
    "        ),\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=valid_loader\n",
    "    )\n",
    "\n",
    "    evaluator.fit(model)\n",
    "    wandb.finish()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate_ensemble(models, valid_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Переносим все модели на главное устройство\n",
    "    main_device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    models = [model.to(main_device) for model in models]\n",
    "    \n",
    "    # Включаем DataParallel только если есть несколько GPU\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        models = [torch.nn.DataParallel(model) for model in models]  # Используем все GPU\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct_ensemble = 0\n",
    "    correct_models = [0] * len(models)  # Для накопления правильных ответов каждой модели\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(valid_loader):\n",
    "            images = images.to(main_device)\n",
    "            labels = labels.to(main_device)\n",
    "            batch_size = labels.size(0)\n",
    "            total += batch_size\n",
    "\n",
    "            # Предсказания ансамбля\n",
    "            ensemble_outputs = []\n",
    "            \n",
    "            # Для каждой модели получаем предсказания и обновляем correct_models\n",
    "            for i, model in enumerate(models):\n",
    "                outputs = model(images)\n",
    "                ensemble_outputs.append(outputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                correct_models[i] += (predicted == labels).sum().item()\n",
    "\n",
    "            # Точность ансамбля\n",
    "            avg_outputs = torch.mean(torch.stack(ensemble_outputs), dim=0)\n",
    "            _, predicted = torch.max(avg_outputs.data, 1)\n",
    "            correct_ensemble += (predicted == labels).sum().item()\n",
    "\n",
    "    # Расчет итоговой точности\n",
    "    ensemble_accuracy = 100 * correct_ensemble / total\n",
    "    model_accuracies = [100 * correct / total for correct in correct_models]\n",
    "\n",
    "    print(f'Ensemble Accuracy: {ensemble_accuracy:.2f}%')\n",
    "    for i, acc in enumerate(model_accuracies):\n",
    "        print(f'Model {i + 1} Accuracy: {acc:.2f}%')\n",
    "\n",
    "    return ensemble_accuracy, model_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.359Z",
     "iopub.execute_input": "2025-05-09T15:55:45.311759Z",
     "iopub.status.busy": "2025-05-09T15:55:45.311191Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wandb/run-20250510_020521-tlhavzdn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/demoren_mipt/neural_ensemble_search_6/runs/tlhavzdn' target=\"_blank\">model_1</a></strong> to <a href='https://wandb.ai/demoren_mipt/neural_ensemble_search_6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/demoren_mipt/neural_ensemble_search_6' target=\"_blank\">https://wandb.ai/demoren_mipt/neural_ensemble_search_6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/demoren_mipt/neural_ensemble_search_6/runs/tlhavzdn' target=\"_blank\">https://wandb.ai/demoren_mipt/neural_ensemble_search_6/runs/tlhavzdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0      | train\n",
      "1 | metrics   | ModuleDict       | 0      | train\n",
      "2 | _model    | DARTS            | 390 K  | train\n",
      "-------------------------------------------------------\n",
      "390 K     Trainable params\n",
      "0         Non-trainable params\n",
      "390 K     Total params\n",
      "1.562     Total estimated model params size (MB)\n",
      "755       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88:  45%|▍| 189/417 [00:19<00:23,  9.77it/s, v_num=vzdn, train_loss=0.0029, train_ac"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "architectures = []\n",
    "for i, architecture in enumerate(arch_dicts):\n",
    "    model = train_model(architecture[\"architecture\"],\n",
    "                        search_train_loader,\n",
    "                        search_valid_loader,\n",
    "                        max_epochs=100,\n",
    "                        learning_rate = 0.025,\n",
    "                        run_name = f\"model_{i}\", \n",
    "                        fast_dev_run=False)\n",
    "    \n",
    "    models.append(model)\n",
    "    if len(models) > 1:\n",
    "        print(f\"Ensemble size: {len(models)}\")\n",
    "        evaluate_ensemble(models, search_valid_loader)\n",
    "    architectures.append(architecture)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(models, search_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate_and_save_results(\n",
    "    models, architectures, valid_loader, folder_name=\"results\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Оценивает модели на валидационном наборе данных и сохраняет результаты в файлы JSON.\n",
    "    Аргументы:\n",
    "    models (list): Список обученных моделей.\n",
    "    architectures (list): Список архитектур моделей.\n",
    "    valid_loader (DataLoader): DataLoader для валидационных данных.\n",
    "    folder_name (str, необязательно): Имя папки для сохранения результатов. По умолчанию \"results\".\n",
    "    Исключения:\n",
    "    ValueError: Если количество моделей и архитектур не совпадает.\n",
    "    Результаты:    Для каждой модели создается файл JSON с результатами, содержащий:\n",
    "    - architecture: Архитектура модели.\n",
    "    - valid_predictions: Предсказания модели на валидационном наборе данных.\n",
    "    - valid_accuracy: Точность модели на валидационном наборе данных.\n",
    "    \"\"\"\n",
    "    if len(models) != len(architectures):\n",
    "        raise ValueError(\"Количество моделей и архитектур должно совпадать\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    for i, (model, architecture) in enumerate(zip(models, architectures)):\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_total = 0\n",
    "        valid_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                valid_preds.extend(predicted.cpu().tolist())\n",
    "                valid_correct += (predicted == labels).sum().item()\n",
    "                valid_total += labels.size(0)\n",
    "\n",
    "        valid_accuracy = valid_correct / valid_total\n",
    "\n",
    "        result = {\n",
    "            \"architecture\": architecture,\n",
    "            \"valid_predictions\": valid_preds,\n",
    "            \"valid_accuracy\": valid_accuracy,\n",
    "        }\n",
    "\n",
    "        file_name = f\"model_{i+1}_results.json\"\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(result, f, indent=4)\n",
    "\n",
    "        print(f\"Results for model_{i + 1} saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluate_and_save_results(models, architectures, search_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-09T15:58:15.363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!zip -r results.zip /kaggle/working/results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6977610,
     "sourceId": 11749079,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
