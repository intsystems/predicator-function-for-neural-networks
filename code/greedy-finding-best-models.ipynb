{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:30:35.148477Z",
     "iopub.status.busy": "2025-05-09T12:30:35.147723Z",
     "iopub.status.idle": "2025-05-09T12:30:50.015169Z",
     "shell.execute_reply": "2025-05-09T12:30:50.014409Z",
     "shell.execute_reply.started": "2025-05-09T12:30:35.148444Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
      "pytensor 2.27.1 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric --quiet\n",
    "!pip install nni --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:30:50.016978Z",
     "iopub.status.busy": "2025-05-09T12:30:50.016753Z",
     "iopub.status.idle": "2025-05-09T12:30:59.696771Z",
     "shell.execute_reply": "2025-05-09T12:30:59.696236Z",
     "shell.execute_reply.started": "2025-05-09T12:30:50.016960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import json\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import OPTICS, DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import deque\n",
    "\n",
    "# Custom imports\n",
    "import sys\n",
    "sys.path.insert(1, \"/kaggle/input/second-dataset/dependecies\")\n",
    "\n",
    "import GCN\n",
    "from Graph import Graph\n",
    "from data_generator import generate_arch_dicts\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:30:59.697899Z",
     "iopub.status.busy": "2025-05-09T12:30:59.697497Z",
     "iopub.status.idle": "2025-05-09T12:30:59.701413Z",
     "shell.execute_reply": "2025-05-09T12:30:59.700760Z",
     "shell.execute_reply.started": "2025-05-09T12:30:59.697881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_diversity_path = \"/kaggle/input/second-dataset/weights/model_diversity_weights.pth\"\n",
    "model_accuracy_path = \"/kaggle/input/second-dataset/weights/model_accuracy_weights.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:30:59.704625Z",
     "iopub.status.busy": "2025-05-09T12:30:59.703802Z",
     "iopub.status.idle": "2025-05-09T12:31:00.052662Z",
     "shell.execute_reply": "2025-05-09T12:31:00.052052Z",
     "shell.execute_reply.started": "2025-05-09T12:30:59.704596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (gat1): GATv2Conv(8, 16, heads=4)\n",
       "  (gat2): GATv2Conv(64, 64, heads=4)\n",
       "  (gat3): GATv2Conv(256, 64, heads=4)\n",
       "  (gat4): GATv2Conv(256, 16, heads=4)\n",
       "  (res1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (res2): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (res3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (res4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (norm1): GraphNorm(64)\n",
       "  (norm2): GraphNorm(256)\n",
       "  (norm3): GraphNorm(256)\n",
       "  (norm4): GraphNorm(64)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 8\n",
    "output_dim = 128\n",
    "dropout=0.1\n",
    "\n",
    "model_diversity = GCN.GAT(input_dim, output_dim, dropout).to(device)\n",
    "state_dict = torch.load(model_diversity_path, map_location=device, weights_only=True)\n",
    "model_diversity.load_state_dict(state_dict)\n",
    "model_diversity.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:31:00.053580Z",
     "iopub.status.busy": "2025-05-09T12:31:00.053366Z",
     "iopub.status.idle": "2025-05-09T12:31:00.121489Z",
     "shell.execute_reply": "2025-05-09T12:31:00.120803Z",
     "shell.execute_reply.started": "2025-05-09T12:31:00.053563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (gat1): GATv2Conv(8, 4, heads=16)\n",
       "  (gat2): GATv2Conv(64, 16, heads=16)\n",
       "  (gat3): GATv2Conv(256, 16, heads=16)\n",
       "  (gat4): GATv2Conv(256, 4, heads=16)\n",
       "  (res1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (res2): Linear(in_features=64, out_features=256, bias=True)\n",
       "  (res3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (res4): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (norm1): GraphNorm(64)\n",
       "  (norm2): GraphNorm(256)\n",
       "  (norm3): GraphNorm(256)\n",
       "  (norm4): GraphNorm(64)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 8\n",
    "output_dim = 1\n",
    "dropout = 0.4\n",
    "heads = 16\n",
    "\n",
    "model_accuracy = GCN.GAT(input_dim, output_dim, dropout, heads=heads).to(device)\n",
    "state_dict = torch.load(model_accuracy_path, map_location=device, weights_only=True)\n",
    "model_accuracy.load_state_dict(state_dict)\n",
    "model_accuracy.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим гиперпараметры:\n",
    "\n",
    "1. K -- количество моделей в ансамбле\n",
    "2. ALPHA -- трейд-off между точностью и разнообразием, где разнообразие определяется как расстояние эмбеддингов до ансамбля.\n",
    "3. N -- количество моделей в одной эпохе\n",
    "\n",
    "Мы хотим, чтобы в ансамбле были точные модели, поэтому введем $\\gamma$ -- минимальную точность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:31:00.122558Z",
     "iopub.status.busy": "2025-05-09T12:31:00.122333Z",
     "iopub.status.idle": "2025-05-09T12:31:00.125860Z",
     "shell.execute_reply": "2025-05-09T12:31:00.125201Z",
     "shell.execute_reply.started": "2025-05-09T12:31:00.122540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "K = 6\n",
    "ALPHA = 0.9\n",
    "N = 1_000_000\n",
    "M = 65536\n",
    "GAMMA = 0.87\n",
    "BATCH_SIZE = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:31:00.126739Z",
     "iopub.status.busy": "2025-05-09T12:31:00.126482Z",
     "iopub.status.idle": "2025-05-09T12:31:00.140280Z",
     "shell.execute_reply": "2025-05-09T12:31:00.139683Z",
     "shell.execute_reply.started": "2025-05-09T12:31:00.126716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_dist_to_best(best_embs, emb):\n",
    "    \"\"\"\n",
    "    best_embs: tensor [k, d], emb: tensor [d] или [1, d]\n",
    "    возвращает min расстояние от emb до любого из best_embs\n",
    "    \"\"\"\n",
    "    if best_embs.numel() == 0:\n",
    "        return float(\"inf\")\n",
    "    dists = torch.cdist(emb.unsqueeze(0), best_embs, p=2)  # [1, k]\n",
    "    return dists.min().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:31:00.141216Z",
     "iopub.status.busy": "2025-05-09T12:31:00.140960Z",
     "iopub.status.idle": "2025-05-09T12:31:00.160635Z",
     "shell.execute_reply": "2025-05-09T12:31:00.159908Z",
     "shell.execute_reply.started": "2025-05-09T12:31:00.141195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def optimize_architecture_search(\n",
    "    K, M, N, GAMMA, BATCH_SIZE, model_accuracy, model_diversity, device\n",
    "):\n",
    "    \"\"\"\n",
    "    K: размер итогового ансамбля\n",
    "    M: минмальный размер потенциального пула\n",
    "    N: число архитектур за итерацию\n",
    "    GAMMA: порог точности\n",
    "    BATCH_SIZE: размер батча\n",
    "    model_accuracy, model_diversity: ваши GNN‑модели\n",
    "    device: 'cpu' или 'cuda'\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    best_embeddings = []\n",
    "    potential_archs = []\n",
    "    potential_embeddings = []\n",
    "    potential_accuracies = []\n",
    "\n",
    "    while len(best_models) < K:\n",
    "        print(\n",
    "            f\"\\nProgress: {len(best_models)}/{K} selected, pool size {len(potential_archs)}/{M}\"\n",
    "        )\n",
    "\n",
    "        # 1) Сгенерировать архитектуры\n",
    "        arch_dicts = generate_arch_dicts(N, use_tqdm=True)  # list of dicts\n",
    "\n",
    "        # 2) Построить графы и датасет\n",
    "        graphs = [Graph(arch, index=i) for i, arch in enumerate(arch_dicts)]\n",
    "        dataset = GCN.CustomDataset(graphs, use_tqdm=True)\n",
    "        loader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            collate_fn=GCN.collate_graphs,\n",
    "        )\n",
    "\n",
    "        # 3) Извлечь эмбеддинги (numpy)\n",
    "        with torch.no_grad():\n",
    "            emb_acc_np, _ = GCN.extract_embeddings(\n",
    "                model_accuracy, loader, device, use_tqdm=True\n",
    "            )\n",
    "            emb_div_np, _ = GCN.extract_embeddings(\n",
    "                model_diversity, loader, device, use_tqdm=True\n",
    "            )\n",
    "\n",
    "        # 4) Фильтрация по точности\n",
    "        mask = emb_acc_np >= GAMMA  # numpy boolean array, shape (N,)\n",
    "\n",
    "        valid_archs = [arch for arch, ok in zip(arch_dicts, mask) if ok]\n",
    "        valid_div_embs = emb_div_np[mask].astype(np.float16)  # shape (n_valid, d)\n",
    "        valid_accs = emb_acc_np[mask]  # shape (n_valid,)\n",
    "\n",
    "        for arch, emb, acc in zip(valid_archs, valid_div_embs, valid_accs):\n",
    "            potential_archs.append(arch)\n",
    "            potential_embeddings.append(emb)\n",
    "            potential_accuracies.append(acc)\n",
    "\n",
    "        # 6) Очистка временных переменных и сборка мусора\n",
    "        del arch_dicts, graphs, dataset, loader\n",
    "        del emb_acc_np, emb_div_np\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        # 7) Если пул заполнен — выбираем наиболее разнообразные модели\n",
    "        while len(potential_archs) >= M and len(best_models) < K:\n",
    "            if best_embeddings:\n",
    "                best_arr = np.stack(best_embeddings)  # shape (len(best), d)\n",
    "                # Для каждого emb в пуле — минимальное расстояние до best_arr\n",
    "                distances = [\n",
    "                    np.min(np.linalg.norm(emb - best_arr, axis=1))\n",
    "                    for emb in potential_embeddings\n",
    "                ]\n",
    "            else:\n",
    "                # Для первой модели ничем не ограничены\n",
    "                distances = [np.inf] * len(potential_embeddings)\n",
    "\n",
    "            farthest = int(np.argmax(distances))\n",
    "\n",
    "            # Добавляем в лучшие\n",
    "            best_models.append(potential_archs.pop(farthest))\n",
    "            best_embeddings.append(potential_embeddings.pop(farthest))\n",
    "            acc = potential_accuracies.pop(farthest)\n",
    "            print(\n",
    "                f\"Selected #{len(best_models)}/{K}: acc={acc:.4f}, dist={distances[farthest]:.4f}\"\n",
    "            )\n",
    "\n",
    "    return best_models, potential_archs, potential_embeddings, potential_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-09T12:31:00.161516Z",
     "iopub.status.busy": "2025-05-09T12:31:00.161346Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress: 0/6 selected, pool size 0/65536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b7319cb4ab4567b676941f1eac9461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c38967a79f74f109bd0f925bae06c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_models_acc, potential_archs, potential_embeddings, potential_accuracies = (\n",
    "    optimize_architecture_search(\n",
    "        K, M, N, GAMMA, BATCH_SIZE, model_accuracy, model_diversity, device\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def select_central_models_by_clusters(\n",
    "    potential_archs,\n",
    "    potential_embeddings,\n",
    "    potential_accuracies,\n",
    "    K,\n",
    "    random_state=42,\n",
    "    plot_pca=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Кластеризует potential_embeddings на K кластеров,\n",
    "    и из каждого выбирает модель, ближайшую к центроиду.\n",
    "\n",
    "    Если plot_pca=True, рисует проекцию всех эмбеддингов и центроидов на плоскость.\n",
    "\n",
    "    Возвращает:\n",
    "        selected_archs: список выбранных архитектур (K штук)\n",
    "        selected_embs: соответствующие эмбеддинги\n",
    "        selected_accs: соответствующие точности\n",
    "    \"\"\"\n",
    "    potential_embeddings = np.array(potential_embeddings, dtype=np.float32)\n",
    "    potential_accuracies = np.array(potential_accuracies, dtype=np.float32)\n",
    "\n",
    "    # 1. Кластеризация\n",
    "    kmeans = KMeans(n_clusters=K, random_state=random_state, n_init='auto')\n",
    "    cluster_ids = kmeans.fit_predict(potential_embeddings)\n",
    "    centroids = kmeans.cluster_centers_\n",
    "\n",
    "    selected_archs = []\n",
    "    selected_embs = []\n",
    "    selected_accs = []\n",
    "    selected_indices = []\n",
    "\n",
    "    for cluster_id in range(K):\n",
    "        cluster_indices = np.where(cluster_ids == cluster_id)[0]\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        cluster_embs = potential_embeddings[cluster_indices]\n",
    "        cluster_centroid = centroids[cluster_id]\n",
    "\n",
    "        dists = np.linalg.norm(cluster_embs - cluster_centroid, axis=1)\n",
    "        best_local_idx = np.argmin(dists)\n",
    "        best_idx_in_global = cluster_indices[best_local_idx]\n",
    "\n",
    "        selected_archs.append(potential_archs[best_idx_in_global])\n",
    "        selected_embs.append(potential_embeddings[best_idx_in_global])\n",
    "        selected_accs.append(potential_accuracies[best_idx_in_global])\n",
    "        selected_indices.append(best_idx_in_global)\n",
    "\n",
    "    if plot_pca:\n",
    "        # PCA до 2 измерений\n",
    "        pca = PCA(n_components=2, random_state=random_state)\n",
    "        projected_embeddings = pca.fit_transform(potential_embeddings)\n",
    "        projected_centroids = pca.transform(centroids)\n",
    "        projected_selected = projected_embeddings[selected_indices]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(projected_embeddings[:, 0], projected_embeddings[:, 1],\n",
    "                    c=cluster_ids, cmap=\"tab10\", alpha=0.4, label=\"Все модели\")\n",
    "        plt.scatter(projected_centroids[:, 0], projected_centroids[:, 1],\n",
    "                    c=\"black\", marker=\"X\", s=100, label=\"Центроиды\")\n",
    "        plt.scatter(projected_selected[:, 0], projected_selected[:, 1],\n",
    "                    c=\"red\", marker=\"*\", s=150, label=\"Выбранные модели\")\n",
    "        plt.title(\"PCA проекция эмбеддингов\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return selected_archs, selected_embs, selected_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_models_cluster, best_embeddings_cluster, best_accuracies_cluster = select_central_models_by_clusters(\n",
    "    potential_archs, potential_embeddings, potential_accuracies, K, random_state=42, plot_pca=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_models_to_dir(best_models, dir_name):\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    \n",
    "    # Сохраняем архитектуры по одной\n",
    "    for i, arch in enumerate(best_models, 1):\n",
    "        file_path = os.path.join(dir_name, f\"model_{i:02d}.json\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(arch, f, indent=4)\n",
    "        print(f\"Сохранена модель {i} в {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_models_to_dir(best_models_cluster, \"best_models_greed_cluster\")\n",
    "save_models_to_dir(best_models_acc, \"best_models_greed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!zip -r best_models best_models_greed\n",
    "!zip -r best_models best_models_greed_cluster"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12228818,
     "datasetId": 6977610,
     "sourceId": 11747078,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
